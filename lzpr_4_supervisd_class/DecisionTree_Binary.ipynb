{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Entolopy  \n",
    "With binary class `y==0 or 1`, definition of informaiton entropy is as follows.   \n",
    "$H(y)=-p(y==0)log_2p(y==0)-p(y==1)log_2p(y==1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y to be 1D numpy array \n",
    "def entropy(y):\n",
    "    # y = 0 or 1 \n",
    "    N = len(y) \n",
    "    s1 = (y==1).sum() \n",
    "    if 0 == s1 or N == s1:\n",
    "        return 0  # no variation, entropy is zero \n",
    "    p1 = float(s1)/N \n",
    "    p0 = 1- p1 \n",
    "    return -p0*np.log2(p0) - p1*np.log2(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0\n",
      "0.9182958340544896\n"
     ]
    }
   ],
   "source": [
    "# Quick test of entropy()\n",
    "print(entropy(np.array([0,0,0,1,1,1])))\n",
    "print(entropy(np.array([0,0,0,0,0,0])))\n",
    "print(entropy(np.array([0,0,1,1,1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain  \n",
    "Both `x and y` are 1D array.   \n",
    "Given a threshold value to `x` as `split`, calculate information gain from the split.  \n",
    "$IG(x,y\\mid{split}) = 1 - p(x<split)H(y\\mid{x<split}) - p(x\\geq{split})H(y\\mid{x\\geq{split}})$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y to be 1D numpy array with same length (x=input variable, y=target class(0 or 1))\n",
    "# split is threshold value to x to make split \n",
    "def information_gain(x, y, split): \n",
    "    y0 = y[x < split]\n",
    "    y1 = y[x >= split]\n",
    "    N = len(y) \n",
    "    y0len = len(y0)\n",
    "    if y0len==0 or y0len==N: \n",
    "        return 0    # already H(y)=0, and result is always 0 even if calculated \n",
    "    p0 = float(len(y0))/N \n",
    "    p1 = 1 - p0 \n",
    "    return entropy(y) - p0*entropy(y0) - p1*entropy(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Quick test of information_gain() \n",
    "x = np.array([0,0,0,0,0,0]); y = np.array([0,0,0,0,0,0]); split=0.5\n",
    "print( information_gain(x,y,split) )\n",
    "\n",
    "x = np.array([1,1,1,0,0,0]); y = np.array([1,1,1,0,0,0]); split=0.5\n",
    "print( information_gain(x,y,split) )\n",
    "\n",
    "x = np.array([1.,2.,3.,7.,8.,9.]); y = np.array([1.,1.,1.,0.,0.,0.]); split=5.0\n",
    "print( information_gain(x,y,split) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best Split that gives Maximum Information Gain for a specified feature  \n",
    "`X={NxD}` input training data and `Y={N,1}` target training data.  `Y` is either 0 or 1.  \n",
    "`col` is column index to `X`.  `X[:,col]` is extracted at the beginning of thsi function.   \n",
    "Then, both `x_values=X[:,col]` and `Y` are sorted in ascending order of `x_values`. \n",
    "With sorted `Y`, the boundary of different class is examined as caididate points to calculate infomration gain.   \n",
    "Threshold for potential `split` is calculated as midpoint of `x_values` over the boundary position.  \n",
    "Return the maximum information gain found, and the `split` value used for the maximum's case.  \n",
    "If this `col` gives maximum information gain w.r.t. the other columns in X, then both `col` and `split` is kept as information for the decision tree node for prediction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3]\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [1 1 0]]\n",
      "(array([0, 1, 2, 2], dtype=int64), array([0, 1, 0, 1], dtype=int64))\n",
      "[0 1 2 2]\n",
      "[0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# quick confirmation of np.nonzero() usage \n",
    "y_values = np.array([0,0,1,1,0,0])\n",
    "boundaries = np.nonzero(y_values[:-1] != y_values[1:])\n",
    "\n",
    "# np.nonzero(a) return tuple of arrays, one for each dimension of a. \n",
    "# In this case, input is 1D, so we're interested only in 1st element of tupple. \n",
    "print(boundaries[0]) # [1 3] is expectd \n",
    "\n",
    "# example from numpy doc. \n",
    "# (row,col) for non-zero is (0,0), (1,1), (2,0), (2,1)\n",
    "x = np.array([[1,0,0], \n",
    "              [0,2,0], \n",
    "              [1,1,0]])\n",
    "print(x)\n",
    "y = np.nonzero(x) \n",
    "print(y)\n",
    "print(y[0])  # row index      [0 1 2 2]\n",
    "print(y[1])  # column index   [0 1 0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split(X, Y, col): \n",
    "    x_values = X[:,col]\n",
    "    sort_idx = np.argsort(x_values)  # index of the sorted \n",
    "    x_values = x_values[sort_idx]\n",
    "    y_values = Y[sort_idx] \n",
    "    \n",
    "    #print(x_values)\n",
    "    #print(y_values)\n",
    "    \n",
    "    # get boundary of different target y \n",
    "    boundaries = np.nonzero(y_values[:-1] != y_values[1:])[0]\n",
    "    #print(boundaries)\n",
    "    \n",
    "    best_split = None \n",
    "    max_ig = 0 \n",
    "    for b in boundaries: \n",
    "        # set split to middle point of boundary \n",
    "        split = (x_values[b] + x_values[b+1]) / 2 \n",
    "        # calculate information gain \n",
    "        ig = information_gain(x_values, y_values, split) \n",
    "        if ig > max_ig: \n",
    "            max_ig = ig\n",
    "            best_split = split \n",
    "    \n",
    "    return max_ig, best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 5.5)\n"
     ]
    }
   ],
   "source": [
    "# simple test of find_split() \n",
    "X = np.array([[2,3,4,8,9,7]]).T\n",
    "Y = np.array([1,1,1,0,0,0])\n",
    "print(find_split( X, Y, 0 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TreeNode class   \n",
    "For simplicity, this handles only binary label with values either 0 or 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode: \n",
    "    \n",
    "    # class variable for maximum depth \n",
    "    max_depth_used = 0\n",
    "    \n",
    "    def __init__(self, depth=0, max_depth=None):\n",
    "        self.depth = depth \n",
    "        self.max_depth = max_depth \n",
    "        if self.depth == 0: \n",
    "            TreeNode.max_depth_used = 0\n",
    "        elif depth > TreeNode.max_depth_used:\n",
    "            TreeNode.max_depth_used = depth\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        if len(Y)==1 or len(set(Y))==1: \n",
    "            # already single class, i.e., leaf node \n",
    "            self.col = None\n",
    "            self.split = None \n",
    "            self.left = None \n",
    "            self.right = None \n",
    "            self.prediction = Y[0]\n",
    "        else:\n",
    "            D = X.shape[1]\n",
    "            cols = range(D) \n",
    "                        \n",
    "            # find the column whose separation gives maximum information gain \n",
    "            max_ig = 0 \n",
    "            best_col = None \n",
    "            best_split = None \n",
    "            for col in cols:\n",
    "                ig, split = find_split(X, Y, col) \n",
    "                if ig > max_ig: \n",
    "                    max_ig = ig\n",
    "                    best_col = col\n",
    "                    best_split = split\n",
    "                    \n",
    "            # maximum information gain == 0, then no way to split any more\n",
    "            # use majority voting as prediction value \n",
    "            if max_ig == 0: \n",
    "                # col=None & split=None : prediction single value \n",
    "                self.col = None\n",
    "                self.split = None \n",
    "                self.left = None \n",
    "                self.right = None \n",
    "                self.prediction = np.round(Y.mean())\n",
    "            else:\n",
    "                self.col = best_col\n",
    "                self.split = best_split \n",
    "                \n",
    "                # check against max_depth \n",
    "                # if already at max_depth, prepare 2 prediction values based on majority after split \n",
    "                if self.depth == self.max_depth: \n",
    "                    self.left = None \n",
    "                    self.right = None \n",
    "                    self.prediction = [ \n",
    "                        np.round( Y[X[:,best_col] < self.split].mean() ),\n",
    "                        np.round( Y[X[:,best_col] >= self.split].mean() ),\n",
    "                    ]\n",
    "                else:\n",
    "                    # split X,Y based on split and make recursive \n",
    "                    left_idx = (X[:,best_col]<best_split)\n",
    "                    right_idx = (X[:,best_col]>=best_split)\n",
    "                                        \n",
    "                    Xleft = X[left_idx] ;   Yleft = Y[left_idx]    \n",
    "                    self.left = TreeNode( self.depth+1, self.max_depth ) \n",
    "                    self.left.fit(Xleft, Yleft)\n",
    "                    \n",
    "                    Xright = X[right_idx];  Yright = Y[right_idx]\n",
    "                    self.right = TreeNode( self.depth+1, self.max_depth ) \n",
    "                    self.right.fit(Xright, Yright) \n",
    "        return\n",
    "                    \n",
    "    def predict_one(self, x):\n",
    "        if self.col is not None and self.split is not None:\n",
    "            feature = x[self.col]\n",
    "            if feature < self.split:\n",
    "                if self.left: \n",
    "                    # recursion \n",
    "                    p = self.left.predict_one(x) \n",
    "                else:\n",
    "                    # pre-allocated calss as left \n",
    "                    p = self.prediction[0]\n",
    "            else:\n",
    "                if self.right:\n",
    "                    # recursion \n",
    "                    p = self.right.predict_one(x)\n",
    "                else:\n",
    "                    # pre-allocated class as right \n",
    "                    p = self.prediction[1]\n",
    "        else:\n",
    "            # pre-allocated class for leaf node \n",
    "            p = self.prediction \n",
    "        return p\n",
    "    \n",
    "    def predict(self, X):\n",
    "        N = len(X) # row size \n",
    "        P = np.zeros(N) \n",
    "        for i in range(N): \n",
    "            P[i] = self.predict_one(X[i])\n",
    "        return P\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper class  \n",
    "Just to appear as if sklern... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree: \n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth \n",
    "        \n",
    "    def fit(self, X,  Y):\n",
    "        self.root = TreeNode(max_depth=self.max_depth)\n",
    "        self.root.fit(X,Y)\n",
    "        self.max_depth_used_ = TreeNode.max_depth_used\n",
    "        \n",
    "    def predict(self,X):\n",
    "        return self.root.predict(X)\n",
    "    \n",
    "    def score(self, X, Y): \n",
    "        P = self.predict(X) \n",
    "        return np.mean(P==Y) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data \n",
    "Xall,Yall = get_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8816, 784), (8816,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this binary dicision tree, use only label==0 & ==1 \n",
    "idx = np.logical_or(Yall==0, Yall==1) \n",
    "X = Xall[idx]\n",
    "Y = Yall[idx]\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4408, 784), (4408,))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and Test data split\n",
    "Ntrain = len(Y) // 2\n",
    "Xtrain, Ytrain = X[:Ntrain], Y[:Ntrain]\n",
    "Xtest, Ytest = X[Ntrain:], Y[Ntrain:]\n",
    "Xtrain.shape, Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Time: 0:00:25.721000\n",
      "Train Accuracy: 1.0\n",
      "Time to compute train accuracy 0:00:00.010000\n",
      "Test Accuracy: 0.9945553539019963\n",
      "Time to compute test accuracy 0:00:00.010000\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTree() \n",
    "\n",
    "t0 = datetime.now() \n",
    "model.fit(Xtrain, Ytrain) \n",
    "print(\"Train Time:\", (datetime.now()-t0))\n",
    "\n",
    "t0 = datetime.now() \n",
    "print(\"Train Accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Time to compute train accuracy\", (datetime.now() - t0))\n",
    "\n",
    "t0 = datetime.now() \n",
    "print(\"Test Accuracy:\", model.score(Xtest, Ytest))\n",
    "print(\"Time to compute test accuracy\", (datetime.now()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum depth used during fit\n",
    "model.max_depth_used_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
