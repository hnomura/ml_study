{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano ANN basic pattern  \n",
    "\n",
    "```\n",
    "import theano\n",
    "import theano.tensor as T  \n",
    "\n",
    "# input layer NxD \n",
    "# hidden layer DxM \n",
    "# output layer MxK \n",
    "\n",
    "# Initial value for weights/biases\n",
    "W1_init = np.randam.randn(D,M) / np.sqrt(D) \n",
    "b1_init = np.zero(M)\n",
    "W2_init = np.random.randn(M,K) / np.sqrt(M) \n",
    "b2_init = np.zero(K)\n",
    "\n",
    "# Input/Target as Theano Matrix \n",
    "thX = T.matrix('X') \n",
    "thT = T.matrix('T')\n",
    "\n",
    "# Weights/biases as Theano Shared variable, with initial value specified\n",
    "W1 = theano.shared(W1_init, 'W1') \n",
    "b1 = theano.shared(b1_init, 'b1') \n",
    "W2 = theano.shared(W2_init, 'W2') \n",
    "b2 = theano.shared(b2_init, 'b2') \n",
    "\n",
    "# Network model \n",
    "thZ = T.nnet.relu( thX.dot(W1) + b1 ) \n",
    "thY = T.nnet.softmax( thZ.dot(W2) + b2 ) \n",
    "\n",
    "# Define cost model (cross entropy) \n",
    "# reg is regularization factor (L2 regularization in this case)  \n",
    "# Since Theano can solve derivetive, we define simply cost function with regularization penalty.  \n",
    "cost = - (thT * T.log(thY)).sum() + reg*( (W1*W1).sum() + (b1*b1).sum() + (W2*W2).sum() + (b2*b2)+sum() ) \n",
    "\n",
    "# Define prediction logic \n",
    "prediction = T.argmax(thY, axis=1) \n",
    "\n",
    "# Training expressions and functions  \n",
    "# lr is learning rate \n",
    "update_W1 = W1 - lr*T.grad(cost, W1) \n",
    "update_b1 = b1 - lr*T.grad(cost, b1) \n",
    "update_W2 = W2 - lr.T.grad(cost, W2) \n",
    "update_b2 = b2 - lr*T.grad(cost, b2) \n",
    "\n",
    "# Define train function \n",
    "train = theano.function(\n",
    "    inputs=[thX, thY],  \n",
    "    updates=[(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2) ], \n",
    "    )\n",
    "    \n",
    "# Define predict function, which generates predication and cost \n",
    "get_predict = theano.function( \n",
    "    inputs=[thX, thT], \n",
    "    outputs=[cost, prediction], \n",
    "    ) \n",
    "    \n",
    "# Training Loop \n",
    "for _ in range(1000): \n",
    "    \n",
    "    # take Xbatch, Ybatch as numpy array, and run train function \n",
    "    train( Xbatch, Ybatch) \n",
    "    \n",
    "    # run get_predict function (with validation data) \n",
    "    cost_val, prediction_val = get_predict( Xtest, Ytest ) \n",
    "    \n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
